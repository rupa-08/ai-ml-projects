{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51623df8-83b9-4f54-bcb4-2b3d3a0beb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 13.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3b3fd8-fb39-460f-b2a9-b39981ff1244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.156 ðŸš€ Python-3.12.7 torch-2.7.1 CPU (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./data/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 124.7Â±67.3 MB/s, size: 35.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learnin\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 258.0Â±40.4 MB/s, size: 52.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.978      3.513      1.609         91        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766     0.0274      0.479      0.206      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       2/50         0G      1.461      1.762      1.177        122        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.948     0.0807      0.211       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/50         0G      1.382      1.467      1.121        102        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.938     0.0583      0.243      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/50         0G       1.33      1.287      1.107        130        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.755      0.276       0.35      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/50         0G      1.329      1.187      1.094        111        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.54      0.313      0.349      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/50         0G      1.347      1.192      1.106        167        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.57      0.461      0.487      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/50         0G      1.338      1.164      1.098        134        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.596      0.605      0.633      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/50         0G      1.284      1.098      1.093         70        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.673      0.555      0.573      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/50         0G      1.285      1.051      1.086         96        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.863      0.461      0.553      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/50         0G      1.234     0.9713      1.074        104        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.704      0.581      0.648      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      11/50         0G      1.231     0.9641      1.075         94        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.77      0.594      0.641      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/50         0G      1.234     0.9483      1.081         70        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.678      0.486      0.558      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      13/50         0G      1.246      0.933      1.074        149        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.706      0.659       0.64      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/50         0G      1.222      0.861      1.068        102        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.682      0.601       0.63      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/50         0G      1.205     0.8454      1.048        184        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.697      0.623       0.66      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/50         0G      1.198     0.8209      1.045        135        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.874      0.595       0.71      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      17/50         0G      1.226     0.8251      1.051         88        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.815      0.604      0.703      0.467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      18/50         0G      1.189     0.7951      1.047        142        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.775      0.656      0.722       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      19/50         0G      1.162     0.7897      1.043        110        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.772      0.742      0.778      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      20/50         0G       1.18     0.7713      1.033        154        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.77      0.584      0.667      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      21/50         0G      1.198     0.7929      1.048        124        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.84       0.67      0.765      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      22/50         0G      1.168     0.7349      1.016         91        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.841      0.627      0.715      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      23/50         0G      1.139     0.7159      1.029        120        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.88      0.614      0.746      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      24/50         0G      1.102     0.7009      1.023         90        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.86      0.656       0.73      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      25/50         0G      1.116     0.7037      1.008        110        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.779       0.64      0.708      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      26/50         0G      1.122     0.7242      1.026         89        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.84      0.616      0.727      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      27/50         0G      1.114     0.6903      1.023        185        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.841       0.71      0.778      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      28/50         0G      1.136     0.7068      1.006        116        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.857      0.731      0.791      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      29/50         0G      1.135     0.6899      1.015        101        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.926      0.709      0.812      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      30/50         0G      1.121     0.6657      1.018         88        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.828      0.758      0.802      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      31/50         0G      1.137     0.6787      1.011        194        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.819      0.645      0.758      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      32/50         0G       1.09     0.6487      1.006        118        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.922      0.715      0.793      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      33/50         0G      1.128     0.6567      1.002        123        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.922      0.725      0.807      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      34/50         0G      1.052     0.6287     0.9941        139        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.834      0.756      0.806      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      35/50         0G      1.045     0.6239     0.9962        101        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766        0.9      0.708      0.805      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      36/50         0G      1.082      0.641      1.006        128        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.795      0.735      0.788      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      37/50         0G      1.044     0.6042       0.98        123        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.867      0.765       0.83      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      38/50         0G      1.064     0.6074     0.9836        244        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.92       0.79      0.837      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      39/50         0G      1.032     0.6051     0.9829        111        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.959      0.723      0.832      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      40/50         0G      1.011      0.582     0.9855        116        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.93      0.732      0.818      0.551\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      41/50         0G      1.002     0.5554     0.9621         97        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.922      0.748      0.826      0.568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      42/50         0G     0.9878      0.545     0.9532        156        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.881      0.764      0.823      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      43/50         0G     0.9794      0.541     0.9628         54        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.898      0.737      0.825      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      44/50         0G     0.9873     0.5303     0.9718         71        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.937      0.755      0.833       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      45/50         0G     0.9663       0.51       0.95        134        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.948      0.763      0.836      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      46/50         0G     0.9518     0.4946     0.9482         58        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.881      0.777      0.836      0.564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      47/50         0G     0.9598     0.5048     0.9536         83        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.912      0.741      0.834      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      48/50         0G     0.9356     0.4943     0.9384         73        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.931      0.736      0.832      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      49/50         0G     0.9274     0.4891     0.9464         73        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.947      0.727      0.829      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      50/50         0G     0.9335     0.4924     0.9484         66        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766       0.94      0.741      0.829      0.569\n",
      "\n",
      "50 epochs completed in 2.164 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.156 ðŸš€ Python-3.12.7 torch-2.7.1 CPU (Apple M4 Pro)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.947      0.727      0.829      0.572\n",
      " mask_weared_incorrect         12         14          1      0.691       0.79      0.576\n",
      "             with_mask        157        636      0.974      0.874      0.964      0.678\n",
      "          without_mask         57        116      0.866      0.616      0.733      0.462\n",
      "Speed: 0.5ms preprocess, 73.7ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_results = model.train(data= \"./data/data.yaml\",\n",
    "                           epochs=50,\n",
    "                           imgsz=640,\n",
    "                           batch=32,\n",
    "                           device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c6aebb-b579-4cf3-b219-85b794f4e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.156 ðŸš€ Python-3.12.7 torch-2.7.1 CPU (Apple M4 Pro)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1661.0Â±308.8 MB/s, size: 47.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        171        766      0.947      0.727      0.829      0.572\n",
      " mask_weared_incorrect         12         14          1      0.691       0.79      0.576\n",
      "             with_mask        157        636      0.974      0.874      0.964      0.678\n",
      "          without_mask         57        116      0.866      0.616      0.733      0.462\n",
      "Speed: 0.7ms preprocess, 81.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      "\n",
      "image 1/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss110_png.rf.35400f14ac4a4a9c397f2d8ce7301bc3.jpg: 640x640 2 mask_weared_incorrects, 13 with_masks, 24 without_masks, 39.6ms\n",
      "image 2/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss130_png.rf.80324879e50dfab32f4359eb9129ad6d.jpg: 640x640 1 mask_weared_incorrect, 3 without_masks, 36.9ms\n",
      "image 3/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss149_png.rf.a1187d652cbc0d8cc2b1fcca793fcd98.jpg: 640x640 6 with_masks, 1 without_mask, 36.8ms\n",
      "image 4/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss158_png.rf.797eaa37d899e2f9ac801b35e55e8b50.jpg: 640x640 14 with_masks, 38.6ms\n",
      "image 5/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss165_png.rf.e1080767765c9026491c6a3036d772de.jpg: 640x640 2 with_masks, 34.0ms\n",
      "image 6/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss166_png.rf.9d0e9dec851612b71a5732e5423970ff.jpg: 640x640 5 with_masks, 36.3ms\n",
      "image 7/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss177_png.rf.4bf5d1a5c93484ba91bbf93625ae0ac8.jpg: 640x640 3 with_masks, 34.3ms\n",
      "image 8/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss178_png.rf.843d400089e33b4d5a385cba21ac5f85.jpg: 640x640 1 with_mask, 1 without_mask, 36.4ms\n",
      "image 9/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss179_png.rf.9995d83df2aebe5f62eef1f6d2b52ea9.jpg: 640x640 4 with_masks, 2 without_masks, 34.2ms\n",
      "image 10/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss198_png.rf.3760108a9fa578ad5da3e1cb2cdfd06f.jpg: 640x640 1 with_mask, 37.1ms\n",
      "image 11/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss201_png.rf.d1a9ace340ce7754002de03c3af9ce57.jpg: 640x640 13 with_masks, 36.7ms\n",
      "image 12/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss208_png.rf.00a9ac2763055cea76d6e7ccc65d91bb.jpg: 640x640 2 with_masks, 35.1ms\n",
      "image 13/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss228_png.rf.9019b85ef16b4e5d399f61519254bb78.jpg: 640x640 1 with_mask, 35.5ms\n",
      "image 14/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss237_png.rf.757a5196422a26c63f86c91df181ab49.jpg: 640x640 2 with_masks, 34.3ms\n",
      "image 15/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss240_png.rf.a60752ee6496e3683bd855c29d6ccb12.jpg: 640x640 1 mask_weared_incorrect, 8 with_masks, 51 without_masks, 34.1ms\n",
      "image 16/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss242_png.rf.550f40dde3f6a619f4b82523a090723c.jpg: 640x640 1 with_mask, 36.6ms\n",
      "image 17/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss259_png.rf.64d9a992faedc653d65e96fd714ae50b.jpg: 640x640 1 with_mask, 36.0ms\n",
      "image 18/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss25_png.rf.af69a7875b51f6c7bda02c2cb26962fd.jpg: 640x640 1 with_mask, 33.9ms\n",
      "image 19/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss268_png.rf.1296dc4c4e560d5d331be1394d7b4d8c.jpg: 640x640 1 with_mask, 36.0ms\n",
      "image 20/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss279_png.rf.82b05a2d753ea1da4d5a0dc890e176b5.jpg: 640x640 2 with_masks, 1 without_mask, 33.3ms\n",
      "image 21/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss288_png.rf.be2ed219b6afdf6bc2dd9ea22b147fcc.jpg: 640x640 2 with_masks, 42.0ms\n",
      "image 22/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss292_png.rf.33f2ab78bd62458947ba9d4dc5961a37.jpg: 640x640 (no detections), 30.4ms\n",
      "image 23/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss306_png.rf.fd4510d3ee92edac81748a55d3813841.jpg: 640x640 1 with_mask, 37.2ms\n",
      "image 24/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss312_png.rf.5619bf326640b5a290fa31c76bdcc806.jpg: 640x640 3 with_masks, 31.5ms\n",
      "image 25/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss315_png.rf.c95b4581a02ebc323241b6abefd9f187.jpg: 640x640 2 with_masks, 32.5ms\n",
      "image 26/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss321_png.rf.14348bb7bad5605014dfdd75dc623a84.jpg: 640x640 1 mask_weared_incorrect, 1 without_mask, 33.9ms\n",
      "image 27/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss327_png.rf.3d57994c966c9a52ce232b731b91a80d.jpg: 640x640 2 with_masks, 6 without_masks, 32.3ms\n",
      "image 28/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss356_png.rf.9ee534de3b76d7cce64923f11fbea56a.jpg: 640x640 1 with_mask, 33.3ms\n",
      "image 29/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss35_png.rf.ec1dcfe04b35992a21b3a908a219a351.jpg: 640x640 2 with_masks, 1 without_mask, 34.3ms\n",
      "image 30/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss374_png.rf.bfa39b953f1bd936b439c16cf70b49f0.jpg: 640x640 4 with_masks, 1 without_mask, 33.3ms\n",
      "image 31/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss384_png.rf.6da437e94be9ae3d3aad25abfc7b36c7.jpg: 640x640 3 with_masks, 34.3ms\n",
      "image 32/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss38_png.rf.6a6f28b92796aaf7eae7acfbb00f2fed.jpg: 640x640 1 with_mask, 1 without_mask, 33.3ms\n",
      "image 33/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss39_png.rf.dfc06944199526f7cdab047141940e74.jpg: 640x640 2 with_masks, 34.8ms\n",
      "image 34/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss408_png.rf.2f2090ef91a5396e2eb03bb2137590ec.jpg: 640x640 8 with_masks, 2 without_masks, 33.0ms\n",
      "image 35/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss415_png.rf.31010ed33056034e52c100b254ac1a2a.jpg: 640x640 1 with_mask, 34.1ms\n",
      "image 36/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss430_png.rf.784195ff8a9539430f8143d2a34cd135.jpg: 640x640 2 with_masks, 35.4ms\n",
      "image 37/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss446_png.rf.7a603d4e8f5b5d2ddf03052844e004d9.jpg: 640x640 1 with_mask, 34.3ms\n",
      "image 38/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss447_png.rf.41609d0309bd4821c3f0703cec826410.jpg: 640x640 3 with_masks, 34.5ms\n",
      "image 39/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss448_png.rf.9c9166d1614fc33ffbf2d0a4e122df1a.jpg: 640x640 6 with_masks, 33.8ms\n",
      "image 40/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss452_png.rf.5662e751118d7616c357a10683dbd04c.jpg: 640x640 3 with_masks, 33.1ms\n",
      "image 41/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss465_png.rf.c8e4ec7a4264378b9372d8c26e6bb729.jpg: 640x640 1 with_mask, 41.1ms\n",
      "image 42/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss483_png.rf.7b274b90dd8a2a65bfa687225f6fe6a6.jpg: 640x640 3 with_masks, 1 without_mask, 30.7ms\n",
      "image 43/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss494_png.rf.38e54fe7adba430351f35d3f4f7aad18.jpg: 640x640 1 with_mask, 38.3ms\n",
      "image 44/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss496_png.rf.372bb5bd05ac3fa435682db9ebcf7c47.jpg: 640x640 1 mask_weared_incorrect, 31.8ms\n",
      "image 45/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss497_png.rf.eefc10446d61136c30f50f79f297f426.jpg: 640x640 1 with_mask, 32.6ms\n",
      "image 46/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss504_png.rf.9c0285d39595e7db848e71dac2c51cb1.jpg: 640x640 1 with_mask, 32.8ms\n",
      "image 47/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss50_png.rf.9f2d7abe4a86617954d953d25d6ba69c.jpg: 640x640 2 with_masks, 32.5ms\n",
      "image 48/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss514_png.rf.2026b1828fd0b74107ad930ba4225c07.jpg: 640x640 3 mask_weared_incorrects, 8 with_masks, 2 without_masks, 32.7ms\n",
      "image 49/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss51_png.rf.51903004f26f7286e24180aef430bfe1.jpg: 640x640 1 without_mask, 33.0ms\n",
      "image 50/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss534_png.rf.3d04b3b0080e4767f517b0667fcc55c0.jpg: 640x640 1 mask_weared_incorrect, 7 with_masks, 2 without_masks, 31.6ms\n",
      "image 51/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss539_png.rf.c532dac359e85d0898ca59ce14af9cde.jpg: 640x640 43 with_masks, 2 without_masks, 32.8ms\n",
      "image 52/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss542_png.rf.b5f5023072ab479ca534042db2171e36.jpg: 640x640 1 with_mask, 29.3ms\n",
      "image 53/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss546_png.rf.9101d3e1754c11729c9457d62456c121.jpg: 640x640 1 with_mask, 35.0ms\n",
      "image 54/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss553_png.rf.d69517e3c4b7fa4a2745cd50f1c8d9ba.jpg: 640x640 1 with_mask, 33.0ms\n",
      "image 55/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss566_png.rf.653381d7ca0942f922ef9648204ce044.jpg: 640x640 3 with_masks, 32.2ms\n",
      "image 56/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss576_png.rf.721ea50fcf84e42dd7745e205887737f.jpg: 640x640 2 with_masks, 34.4ms\n",
      "image 57/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss581_png.rf.0e6679896b983c52d2c02496d40539cd.jpg: 640x640 1 with_mask, 33.7ms\n",
      "image 58/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss585_png.rf.2d47e5910f667cad53f300f859ffba2f.jpg: 640x640 3 with_masks, 1 without_mask, 31.8ms\n",
      "image 59/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss58_png.rf.1cd9bbdce8146624adce2848c9630fe3.jpg: 640x640 15 with_masks, 31.8ms\n",
      "image 60/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss598_png.rf.3b5c96aa51b550021afb324fb00299ba.jpg: 640x640 1 with_mask, 31.8ms\n",
      "image 61/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss5_png.rf.7fdfc43582a8c75dd9e6cd8d0115d9f5.jpg: 640x640 1 mask_weared_incorrect, 2 with_masks, 2 without_masks, 29.7ms\n",
      "image 62/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss612_png.rf.f56f3ac33911223a98a9f63fa447fbfd.jpg: 640x640 1 with_mask, 31.5ms\n",
      "image 63/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss648_png.rf.46d17458bf11ce5c3897b5248b9172da.jpg: 640x640 3 with_masks, 29.3ms\n",
      "image 64/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss658_png.rf.b74468592d5ea8bd1ac77fc05a3cba5b.jpg: 640x640 1 mask_weared_incorrect, 31.8ms\n",
      "image 65/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss668_png.rf.03f2d7c61add57be7dedefd9d6adc5cb.jpg: 640x640 1 with_mask, 30.6ms\n",
      "image 66/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss688_png.rf.0571ebd466e44364c042a2b9a52c05fa.jpg: 640x640 1 with_mask, 31.3ms\n",
      "image 67/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss70_png.rf.0b4e35d4041c84c0eccdd800fd59367f.jpg: 640x640 2 with_masks, 3 without_masks, 30.8ms\n",
      "image 68/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss710_png.rf.3832998bc22f5186e840e0cc5973846d.jpg: 640x640 2 with_masks, 1 without_mask, 30.8ms\n",
      "image 69/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss713_png.rf.9a94169cde80163259c8c40675005734.jpg: 640x640 1 with_mask, 30.6ms\n",
      "image 70/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss744_png.rf.9920f0d65d74c02d1ea2a4170a5a8060.jpg: 640x640 2 with_masks, 1 without_mask, 31.0ms\n",
      "image 71/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss750_png.rf.d80d90fb7563dd7e8a3bc4bcf7d8194f.jpg: 640x640 6 without_masks, 30.2ms\n",
      "image 72/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss77_png.rf.be2288bd3ce925e7531d9f3fd158839a.jpg: 640x640 3 with_masks, 31.0ms\n",
      "image 73/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss782_png.rf.c569305d956c160b872a79a4da72dd9c.jpg: 640x640 1 mask_weared_incorrect, 2 with_masks, 33.5ms\n",
      "image 74/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss791_png.rf.a76772527f81f6cf6207ed1a176d0126.jpg: 640x640 1 with_mask, 30.9ms\n",
      "image 75/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss793_png.rf.b12e16fc1383f177b91d156ccc376b25.jpg: 640x640 1 with_mask, 33.7ms\n",
      "image 76/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss802_png.rf.74e3769005c64fe08e3e8275491982ef.jpg: 640x640 4 with_masks, 31.8ms\n",
      "image 77/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss803_png.rf.b061f95775986d26d25bbd2eecdf4b43.jpg: 640x640 1 with_mask, 35.1ms\n",
      "image 78/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss819_png.rf.f1f7dd42b85832d7015da568bf3b270d.jpg: 640x640 1 with_mask, 33.2ms\n",
      "image 79/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss832_png.rf.ae070efa655565fb0dfa84744013655a.jpg: 640x640 1 mask_weared_incorrect, 31.9ms\n",
      "image 80/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss86_png.rf.098233aff3d799b6d1286674670301be.jpg: 640x640 2 with_masks, 2 without_masks, 33.2ms\n",
      "image 81/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss87_png.rf.321b3d619c1869beea3abaaa308950fe.jpg: 640x640 1 with_mask, 34.0ms\n",
      "image 82/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss8_png.rf.cc8fed5146bd156822b1c9d9fd27bd51.jpg: 640x640 1 with_mask, 32.7ms\n",
      "image 83/83 /Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/mask-detection-2/data/test/images/maksssksksss95_png.rf.dc3c9364f640b9552e11ccb937f08dca.jpg: 640x640 1 without_mask, 31.8ms\n",
      "Speed: 0.6ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val() #evaluate model performance on validation set\n",
    "results = model.predict(source='./data/test/images', save=True, conf=0.25)#prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ca212-576f-476e-8862-1d1422e70c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
